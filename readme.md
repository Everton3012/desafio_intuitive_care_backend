# Teste T√©cnico - Est√°gio IntuitiveCare 2026

## Vis√£o Geral

Projeto desenvolvido em Python para coleta, processamento, consolida√ß√£o, valida√ß√£o,
enriquecimento e agrega√ß√£o de dados de despesas das operadoras de sa√∫de a partir da
API de Dados Abertos da ANS.

O projeto foi implementado como um **pipeline automatizado ponta a ponta**, cobrindo integralmente os Testes 1, 2, 3 e 4 do desafio t√©cnico.

---

## Fonte dos Dados

Os dados utilizados no projeto s√£o provenientes da base p√∫blica da ANS
(Ag√™ncia Nacional de Sa√∫de Suplementar):

https://dadosabertos.ans.gov.br/FTP/PDA/

Fontes utilizadas:

- Demonstra√ß√µes Cont√°beis Trimestrais (√∫ltimos 3 trimestres dispon√≠veis)
- Cadastro de Operadoras de Planos de Sa√∫de **Ativas**
- Cadastro de Operadoras de Planos de Sa√∫de **Canceladas**

---

## Tecnologias

- Python 3.10+
- Pandas
- Requests
- BeautifulSoup4
- FastAPI
- PostgreSQL 15
- Docker
- SQL
- Git

---

## Estrutura do Projeto

```
Teste_IntuitiveCare/
‚îÇ
‚îú‚îÄ‚îÄ etl/
‚îÇ   ‚îú‚îÄ‚îÄ download_ans.py
‚îÇ   ‚îú‚îÄ‚îÄ download_operadoras.py
‚îÇ   ‚îú‚îÄ‚îÄ process_files.py
‚îÇ   ‚îú‚îÄ‚îÄ consolidate.py
‚îÇ   ‚îî‚îÄ‚îÄ validate_and_aggregate.py
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ extracted/
‚îÇ   ‚îî‚îÄ‚îÄ final/
‚îÇ
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îú‚îÄ‚îÄ etl.log
‚îÇ   ‚îî‚îÄ‚îÄ validation.log
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ db.py
‚îÇ   ‚îú‚îÄ‚îÄ queries.py
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îú‚îÄ‚îÄ 01_ddl.sql
‚îÇ   ‚îú‚îÄ‚îÄ 02_import.sql
‚îÇ   ‚îî‚îÄ‚îÄ 03_queries.sql
‚îÇ
‚îú‚îÄ‚îÄ logs/
‚îÇ
‚îú‚îÄ‚îÄ run_pipeline.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## Como Executar

### 1. Criar ambiente virtual

```bash
python -m venv .venv
```

### 2. Ativar ambiente virtual

Windows:
```bash
.venv\Scripts\activate
```

Linux/Mac:
```bash
source .venv/bin/activate
```

### 3. Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

---

## Execu√ß√£o do Pipeline Completo (Recomendado)

```bash
python run_pipeline.py
```

Esse comando executa automaticamente:

1. Download dos cadastros de operadoras (ativas e canceladas)
2. Download dos √∫ltimos 3 arquivos trimestrais de demonstra√ß√µes cont√°beis
3. Extra√ß√£o e processamento dos arquivos
4. Consolida√ß√£o com dados cadastrais
5. Valida√ß√£o, enriquecimento e agrega√ß√£o final
6. Gera√ß√£o do arquivo ZIP final exigido no teste

---

## Execu√ß√£o por Etapas (Opcional)

### Download das Demonstra√ß√µes Cont√°beis

```bash
python etl/download_ans.py
```

### Download do Cadastro de Operadoras

```bash
python etl/download_operadoras.py
```
### Processamento e Consolida√ß√£o Inicial (ETL)

```bash
python etl/process_files.py
```

Gera:
```
data/final/despesas_por_operadora_trimestre.csv
```

### Consolida√ß√£o com Dados Cadastrais

```bash
python etl/consolidate.py
```

Gera:
```
data/final/despesas_consolidadas_final.csv
data/final/consolidado_despesas.zip
```

### Valida√ß√£o, Enriquecimento e Agrega√ß√£o (Teste 2)

```bash
python etl/validate_and_aggregate.py
```

Gera:
```
data/final/despesas_agregadas.csv
Teste_Everton_Brandao.zip
```

---

## Executar Banco (PostgreSQL via Docker) + Importar CSVs

> Pr√©-requisito: Docker instalado.

### 1) Subir o container PostgreSQL

Exemplo:

```bash
docker run --name intuitivecare_postgres -e POSTGRES_DB=intuitivecare -e POSTGRES_USER=intuitive -e POSTGRES_PASSWORD=intuitive123 -p 5432:5432 -d postgres:15
```
### 2) Copiar CSVs gerados para dentro do container

```bash
docker cp data/final/despesas_consolidadas_final.csv intuitivecare_postgres:/tmp/despesas_consolidadas_final.csv
docker cp data/final/despesas_agregadas.csv intuitivecare_postgres:/tmp/despesas_agregadas.csv
docker cp data/raw/Relatorio_cadop.csv intuitivecare_postgres:/tmp/Relatorio_cadop.csv
docker cp data/raw/Relatorio_cadop_canceladas.csv intuitivecare_postgres:/tmp/Relatorio_cadop_canceladas.csv
```

### 3) Rodar DDL e Import
```bash
docker exec -i intuitivecare_postgres psql -U intuitive -d intuitivecare -v ON_ERROR_STOP=1 < sql/01_ddl.sql
docker exec -i intuitivecare_postgres psql -U intuitive -d intuitivecare -v ON_ERROR_STOP=1 < sql/02_import.sql
```
### 4) Validar carga

```bash
docker exec -it intuitivecare_postgres psql -U intuitive -d intuitivecare -c "SELECT COUNT(*) operadoras FROM operadoras; SELECT COUNT(*) despesas FROM despesas_consolidadas; SELECT COUNT(*) agregadas FROM despesas_agregadas;"
```

---

## Executar API (FastAPI)

### 1) Criar arquivo `.env` na raiz

Use o `.env.example` como base e crie um `.env` com:

```env
DB_HOST=localhost
DB_PORT=5432
DB_NAME=intuitivecare
DB_USER=intuitive
DB_PASSWORD=intuitive123
```

### 2) Subir o servidor

```bash
uvicorn api.main:app --host 127.0.0.1 --port 8000 --reload
```

### 3) Acessar documenta√ß√£o (Swagger)

- http://127.0.0.1:8000/docs

### 4) Teste r√°pido

```bash
curl -X GET "http://127.0.0.1:8000/health"
curl -X GET "http://127.0.0.1:8000/api/operadoras?page=1&limit=10"
curl -X GET "http://127.0.0.1:8000/api/estatisticas"
```

---

## Teste 2 ‚Äì Transforma√ß√£o e Valida√ß√£o de Dados

### Valida√ß√µes Implementadas

- CNPJ v√°lido (formato + d√≠gitos verificadores)
- Raz√£o Social n√£o vazia
- Valores num√©ricos n√£o negativos

#### Estrat√©gia para CNPJs Inv√°lidos

**Decis√£o adotada:** descarte dos registros com CNPJ inv√°lido.

**Pr√≥s:**
- Evita inconsist√™ncias no enriquecimento
- Garante integridade das agrega√ß√µes
- Simplifica o pipeline

**Contras:**
- Redu√ß√£o do volume final de dados
- Poss√≠vel perda de registros com erro de origem

---

### Enriquecimento de Dados

- Join realizado via `CNPJ`
- Cadastros de operadoras ativas e canceladas s√£o unificados
- Registros sem correspond√™ncia no cadastro s√£o mantidos com campos nulos
- Duplicidades de CNPJ s√£o resolvidas via `drop_duplicates`

Colunas adicionadas:
- RegistroANS
- Modalidade
- UF

---

### Agrega√ß√µes Realizadas

Agrupamento por:
- RazaoSocial
- UF

M√©tricas calculadas:
- Total de despesas
- M√©dia trimestral
- Desvio padr√£o

Ordena√ß√£o:
- Total de despesas (ordem decrescente)

---

## Teste 3 ‚Äì Banco de Dados e An√°lise (PostgreSQL)

### Modelagem e Normaliza√ß√£o

Foi adotada uma abordagem de **modelagem normalizada**, com tabelas separadas para:

- Operadoras
- Despesas consolidadas
- Despesas agregadas

Essa decis√£o permite evitar redund√¢ncia de dados cadastrais, manter integridade
referencial e facilitar an√°lises futuras com menor risco de inconsist√™ncias.


### Trade-offs T√©cnicos ‚Äì Normaliza√ß√£o

**Abordagem escolhida:** Tabelas normalizadas (Op√ß√£o B)

**Justificativa:**

- O volume de dados √© moderado e adequado para normaliza√ß√£o sem impacto negativo
  relevante de performance.
- A frequ√™ncia de atualiza√ß√£o dos dados √© baixa (processamento peri√≥dico),
  reduzindo o custo de joins.
- Queries anal√≠ticas se tornam mais leg√≠veis e f√°ceis de manter.
- Evita duplica√ß√£o de informa√ß√µes cadastrais das operadoras.

**Alternativa considerada (tabela desnormalizada):**
Foi descartada por aumentar redund√¢ncia e dificultar a manuten√ß√£o dos dados
cadastrais ao longo do tempo.

### Tipos de Dados

**Valores monet√°rios:**
Foi utilizado o tipo `DECIMAL` em vez de `FLOAT`, garantindo precis√£o nos c√°lculos
financeiros e evitando erros de arredondamento.

**Datas e per√≠odos:**
- Ano e trimestre foram armazenados separadamente (`SMALLINT`), pois:
  - Facilitam filtros e agrega√ß√µes
  - Evitam parsing de strings
  - S√£o suficientes para o n√≠vel de granularidade do problema

**CNPJ e UF:**
- `VARCHAR` para CNPJ, preservando zeros √† esquerda
- `CHAR(2)` para UF, garantindo padroniza√ß√£o

### Importa√ß√£o e Tratamento de Inconsist√™ncias

A importa√ß√£o dos dados foi realizada utilizando **tabelas de staging**, permitindo
tratamento pr√©vio antes da inser√ß√£o nas tabelas finais.

Durante o processo, foram tratadas as seguintes situa√ß√µes:

- **Encoding:**  
  Arquivos das operadoras utilizam `LATIN1`, enquanto os arquivos de despesas
  utilizam `UTF-8`. O encoding foi tratado explicitamente durante o `COPY`.

- **Valores NULL em campos obrigat√≥rios:**  
  Registros sem CNPJ, Raz√£o Social ou valores num√©ricos v√°lidos foram descartados.

- **Strings em campos num√©ricos:**  
  Valores monet√°rios foram normalizados removendo separadores de milhar e
  convertidos para `DECIMAL`.

- **Duplicidade de CNPJ:**  
  Foi priorizada a operadora ativa em caso de duplicidade, mantendo apenas um
  registro por CNPJ.

Essa abordagem garante maior robustez e evita falhas durante a carga.

### Queries Anal√≠ticas

Foram desenvolvidas queries anal√≠ticas utilizando **CTEs** e **window functions**
para maior clareza e desempenho.

**Query 1 ‚Äì Crescimento percentual de despesas:**
- Calcula o crescimento entre o primeiro e o √∫ltimo trimestre dispon√≠vel por
  operadora.
- Operadoras sem dados completos s√£o mantidas, mas exclu√≠das do ranking caso n√£o
  seja poss√≠vel calcular o crescimento.

**Query 2 ‚Äì Distribui√ß√£o de despesas por UF:**
- Soma total de despesas por UF
- C√°lculo da m√©dia de despesas por operadora em cada estado

**Query 3 ‚Äì Operadoras acima da m√©dia:**
- Identifica operadoras com despesas acima da m√©dia geral em pelo menos 2 dos 3
  trimestres analisados.
- Foi escolhida uma abordagem baseada em agrega√ß√µes e CTEs por oferecer boa
  legibilidade e facilidade de manuten√ß√£o.

---

## Atualiza√ß√£o dos dados (novos trimestres)

O pipeline sempre baixa automaticamente os **√∫ltimos 3 trimestres dispon√≠veis** na ANS.
Quando um novo trimestre √© publicado, basta executar novamente:

```bash
python run_pipeline.py
```
Depois, reimportar os CSVs no PostgreSQL:

```bash
docker exec -i intuitivecare_postgres psql -U intuitive -d intuitivecare -v ON_ERROR_STOP=1 < sql/02_import.sql
```
A estrat√©gia adotada no import √© `TRUNCATE + INSERT`, garantindo consist√™ncia e simplicidade (KISS),
j√° que o volume √© moderado.

---

## Teste 4 ‚Äì API (FastAPI)

Foi implementada uma API em FastAPI para consulta das operadoras e despesas consolidadas
a partir do banco PostgreSQL gerado no Teste 3.

### Rotas implementadas

- `GET /api/operadoras`  
  Lista operadoras com pagina√ß√£o (`page`, `limit`) , filtro opcional `q` (CNPJ ou Raz√£o Social) e filtro opcional `situacao` (ATIVA ou CANCELADA).

- `GET /api/operadoras/{cnpj}`  
  Retorna detalhes de uma operadora espec√≠fica.

- `GET /api/operadoras/{cnpj}/despesas`  
  Retorna o hist√≥rico de despesas da operadora nos 3 trimestres analisados.

- `GET /api/estatisticas`  
  Retorna estat√≠sticas agregadas: total, m√©dia, top 5 operadoras e top 5 UFs por despesas.

- `GET /health`  
  Healthcheck simples com verifica√ß√£o de conex√£o ao banco.

- `POST /api/admin/atualizar`  
  executa a pipeline ,sobe as informa√ß√µes para o banco e devolve as nforma√ßoes para o frontend

### Trade-offs T√©cnicos (Backend)

**Framework:** FastAPI  
Escolhi FastAPI por oferecer tipagem, valida√ß√£o autom√°tica (Pydantic), Swagger/OpenAPI nativo,
boa performance e facilidade de manuten√ß√£o.

**Pagina√ß√£o:** Offset-based (`page/limit` com `OFFSET/LIMIT`)  
Escolhida por simplicidade (KISS) e por o volume ser baixo/moderado (~4k operadoras).  
Para grandes volumes, seria melhor Keyset/Cursor pagination.

**/api/estatisticas:** queries diretas  
As estat√≠sticas s√£o calculadas via SQL no momento da requisi√ß√£o, pois os dados mudam apenas
quando o pipeline √© executado. Em cen√°rio real, poderia ser cacheado por X minutos ou pr√©-calculado.

**Resposta de pagina√ß√£o:** dados + metadados  
Retorna `{ data, total, page, limit }` para facilitar o frontend e evitar chamadas extras.

---

## üß© Vis√£o Geral da Arquitetura

```
Dados P√∫blicos ANS
        ‚Üì
Pipeline Python (ETL)
        ‚Üì
CSVs Consolidados
        ‚Üì
PostgreSQL (Docker)
        ‚Üì
FastAPI
        ‚Üì
Frontend (Vue.js)
```
---

## Logs

- `logs/etl.log`: download, extra√ß√£o, processamento e consolida√ß√£o
- `logs/validation.log`: valida√ß√µes, enriquecimento e agrega√ß√µes

---

## Resultado Final

Arquivos gerados:

- `despesas_por_operadora_trimestre.csv`
- `despesas_consolidadas_final.csv`
- `despesas_agregadas.csv`
- `Teste_Everton_Brandao.zip`

---

## Limita√ß√µes e Melhorias Futuras

- Implementar testes automatizados
- Automatizar a carga no banco ap√≥s a execu√ß√£o do pipeline (ex.: script √∫nico ou docker-compose)

---

## Frontend (Vue.js) ‚Äì Status

A interface web em Vue.js est√° planejada conforme especifica√ß√£o do Teste 4, com:
- tabela paginada de operadoras
- busca por CNPJ/Raz√£o Social
- p√°gina de detalhes com hist√≥rico de despesas
